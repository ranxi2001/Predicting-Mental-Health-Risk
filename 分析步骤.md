### 分析步骤：

#### 1.数据读取（理解数据结构）

#### 2.探索性数据分析EDA（初步洞察变量表现与关联性）

##### （1）缺失值与异常值统计

##### （2）类别变量分布图

目标变量：

心理健康风险： 如果某一类 <10%，极易导致模型忽略该类 → 需要重采样！

输入变量：

性别：关注是否女性占比远大于男性（性别偏倚）

就业状况：检查“学生/自由职业者”是否极度稀缺

工作环境：看“有病史”和“无病史”的占比是否不均

是否有精神病史：是否接受治疗的样本是否均衡

绘制：**类别变量分布图** 

##### 2.3数值变量分布图

目的：识别异常值、偏态性、是否标准化

##### 2.4变量与目标关系图，判断变量是否有区分度

一个变量如果在不同的心理健康风险分组之间**均值或分布差异显著**，那么它对分类模型来说就是**有价值的变量**。

数值变量：（箱型图）搭配anova方差分析

类别变量：**分类标签堆叠图**：输入变量与心理健康风险的堆叠条形图（交叉关系）搭配卡方检验。

| **p < 0.05**   | 差异显著 → 说明该变量对分类有帮助                 |
| -------------- | ------------------------------------------------- |
| ❌ **p ≥ 0.05** | 差异不显著 → 可考虑删除该变量（或非线性建模处理） |

##### 2.5相关性热图：发现变量间的冗余或互斥关系

相关性热图的目的:
1. 发现变量间的相关性强度
2. 识别高度相关的变量对(相关系数>0.7)，考虑删除冗余变量
3. 检查变量与目标变量的相关程度，辅助特征选择


#### 3.数据预处理（保证数据质量与模型适应性）

##### （1）**缺失值处理**

- **连续变量**：使用中位数或均值填充（推荐中位数，抗异常）
- **分类变量**：使用众数填充

##### （2）**分类变量编码**

将非数值型的分类变量（如 性别、就业状况、工作环境）转换为模型可以识别的数值形式。

##### （3）**标准化（Standardization）**

统一所有数值变量的量纲，尤其是当你使用**基于距离或线性回归类模型（如 SVM、Logistic）**时，标准化是必须的。

##### （4）**目标变量编码**

##### （5）划分训练集和测试集



#### 4.特征筛选（选择对分类有效的变量）

1. 初筛：ANOVA 或卡方检验（删除无统计意义变量）
2. 再筛：随机森林 / 逻辑回归输出特征重要性（保留 top 变量）
3. 可选：使用 RFE 进一步包装搜索最优组合



#### 5.模型建立（训练多个模型并调参优化）

**Logistic Regression（逻辑回归）**、**Decision Tree**（决策树）、**Random Forest**（随机森林）、**Gradient Boosting**（如 XGBoost、LightGBM）、**Support Vector Machine**（支持向量机）、**K-Nearest Neighbors**（KNN）、**Naive Bayes**、**Neural Network**（多层感知器 MLP）



#### 6.模型评估（找出最优模型，解释分类机制）

| accuracy（准确率） | 类别分布均衡时使用                            |
| ------------------ | --------------------------------------------- |
| precision / recall | 类别失衡时优先关注（特别是 High 风险 recall） |
| f1-score           | 兼顾准确率与召回率，推荐                      |



| **指标**         | **用途**                       | **解读**                             |
| ---------------- | ------------------------------ | ------------------------------------ |
| accuracy         | 整体分类正确率                 | 不推荐在类别不均衡情况下单独使用     |
| precision        | 预测为某类时，预测对了多少     | 高风险人群中预测精度                 |
| recall（召回率） | 真正的该类被成功识别的比例     | **重点指标：能否找出真正的高风险者** |
| f1-score         | precision 和 recall 的调和均值 | 类别不均衡时推荐                     |

##### 如何解释模型的分类机制？（模型可解释性）

##### （1）**决策树 & 逻辑回归：原生可解释**

| **模型** | **解释方式**                   |
| -------- | ------------------------------ |
| 决策树   | 可视化树结构（决策路径）       |
| 逻辑回归 | 查看变量的系数权重（正负相关） |

##### （2）**随机森林 & XGBoost：特征重要性排序**

- 特征重要性数值越高 → 模型越依赖这个变量做分类；
- 例如：stress_level 得分最高 → 决策最依赖压力水平。

（3） **使用 SHAP 解释任意模型（高级推荐）**

- 输出每个特征在每个预测样本中的正向/负向影响；
- 可解释模型为什么判断某人是“高风险”。